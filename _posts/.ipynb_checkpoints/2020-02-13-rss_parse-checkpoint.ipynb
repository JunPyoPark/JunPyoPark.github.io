{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSS 피드를 활용하여 각종 언론사에서 뉴스 데이터 받기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#RSS-피드를-활용하여-각종-언론사에서-뉴스-데이터-받기\" data-toc-modified-id=\"RSS-피드를-활용하여-각종-언론사에서-뉴스-데이터-받기-1\">RSS 피드를 활용하여 각종 언론사에서 뉴스 데이터 받기</a></span><ul class=\"toc-item\"><li><span><a href=\"#RSS-?\" data-toc-modified-id=\"RSS-?-1.1\">RSS ?</a></span></li><li><span><a href=\"#저작권-이슈\" data-toc-modified-id=\"저작권-이슈-1.2\">저작권 이슈</a></span></li><li><span><a href=\"#RSS-파싱에-필요한-모듈-설치\" data-toc-modified-id=\"RSS-파싱에-필요한-모듈-설치-1.3\">RSS 파싱에 필요한 모듈 설치</a></span><ul class=\"toc-item\"><li><span><a href=\"#RSS-리스트-살펴보기\" data-toc-modified-id=\"RSS-리스트-살펴보기-1.3.1\">RSS 리스트 살펴보기</a></span></li><li><span><a href=\"#RSS-파싱-함수\" data-toc-modified-id=\"RSS-파싱-함수-1.3.2\">RSS 파싱 함수</a></span></li><li><span><a href=\"#기사(article)-정보-확인\" data-toc-modified-id=\"기사(article)-정보-확인-1.3.3\">기사(article) 정보 확인</a></span><ul class=\"toc-item\"><li><span><a href=\"#제목-확인\" data-toc-modified-id=\"제목-확인-1.3.3.1\">제목 확인</a></span></li><li><span><a href=\"#기사-링크-확인\" data-toc-modified-id=\"기사-링크-확인-1.3.3.2\">기사 링크 확인</a></span></li><li><span><a href=\"#기사-요약-확인\" data-toc-modified-id=\"기사-요약-확인-1.3.3.3\">기사 요약 확인</a></span></li></ul></li><li><span><a href=\"#article-본문-파싱하기\" data-toc-modified-id=\"article-본문-파싱하기-1.3.4\">article 본문 파싱하기</a></span></li></ul></li><li><span><a href=\"#마지막으로-다시한번-Warning---뉴스도-저작권-보호를-받습니다!\" data-toc-modified-id=\"마지막으로-다시한번-Warning---뉴스도-저작권-보호를-받습니다!-1.4\">마지막으로 다시한번 Warning - 뉴스도 저작권 보호를 받습니다!</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSS ?\n",
    "\n",
    "`RSS`: Rich Site Summary 또는 Really Simple Syndication. 舊 RDF Site Summary.\n",
    "\n",
    "RSS는, 어떤 사이트에 새로운 콘텐츠가 올라왔을 때 해당 사이트에 방문하지 않고, RSS서비스를 통해 리더 한 곳에서 그 콘텐츠를 이용하기 위한 방법입니다. 쉽게 생각하면, 여러 언론사 사이트를 모두 방문할 필요 없이 다양한 기사를 네이버뉴스 한 곳에서 볼 수 있는 것과 같다고 보면 됩니다.\n",
    "![](https://trello-attachments.s3.amazonaws.com/5b29ec749cfb0d90ada47d03/5e44f83d26cac278468fba3a/a979fbdf7c0e6fe9c99ad4267b34a2ba/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RSS 피드는 아래와 같이 `XML 기반의 문서 포맷`으로 이루어져 있습니다. (조선일보 RSS 예시)\n",
    "\n",
    "\n",
    "![](https://trello-attachments.s3.amazonaws.com/5b29ec749cfb0d90ada47d03/5e44f83d26cac278468fba3a/bfaf0abb522bbfeefbbf469700a3a67f/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "언론사들은 RSS 서비스를 통해 기사의 일부 정보를 제공합니다. 제가 노가다(?)를 통해 최근에도 기사가 올라오고있는 188개의 RSS 주소를 정리하였습니다. 파이썬에서 활용하기 쉽게 피클(pkl)파일로 만들어 두었으니 아래 코드를 따라하시려면 다운받아 주시면 됩니다. (제 마음대로 골라서 빠져있는 언론사도 존재합니다.)\n",
    "\n",
    "[RSS 목록 다운로드](https://trello-attachments.s3.amazonaws.com/5b29ec749cfb0d90ada47d03/5e44f88994f60374cb3b5b59/1dc4257e59a49fb5239f68aa753858c8/rss_list.pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저작권 이슈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "언론사는 `RSS를 통해 콘텐츠의 일부를 제공`하며 **RSS 서비스는 일반인이나 관공서 및 기업등의 이용자가 개인 PC 등 한정된 공간 안에서 뉴스 콘텐트를 개인적으로 구독/이용 하는데 그쳐야 한다고 명시하고 있습니다.**\n",
    "\n",
    "일반인이나 관공서 및 기업이 RSS를 통해 구독하고 있는 뉴스 콘텐트를 홈페이지 또는 인트라넷에 노출해 다수의 이용자에게 보여주는 행위와 재(再)RSS서비스를 하는 행위는 **콘텐츠의 복제 및 공중송신에 해당하므로 저작권자의 허락을 얻어야 합니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://trello-attachments.s3.amazonaws.com/5b29ec749cfb0d90ada47d03/5e44f83d26cac278468fba3a/7ca6286f33b3212e73a04688f19e021a/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSS 파싱에 필요한 모듈 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [feedparser](https://pythonhosted.org/feedparser/) : RSS를 간단하게 파싱하기 위해 필요한 모듈입니다. \n",
    "* [requests](https://pypi.org/project/requests/2.7.0/) : Requests is an Apache2 Licensed HTTP library, written in Python, for human beings.\n",
    "* [goose3](https://github.com/goose3/goose3) : 기사 본문을 편리하게 파싱가능한 모듈입니다. (Python 3 기준)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import feedparser\n",
    "import requests\n",
    "from goose3 import Goose\n",
    "from goose3.text import StopWordsKorean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSS 리스트 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다운 받은 rss_list.pkl을 주피터 노트북과 같은 폴더에 옮긴 뒤 읽어와 내용을 살펴봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rss_list.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: E722\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                             is_text=False)\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rss_list.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 return read_wrapper(\n\u001b[1;32m--> 173\u001b[1;33m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[0;32m    174\u001b[0m             \u001b[1;31m# compat pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                             is_text=False)\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rss_list.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(path, compression)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: E722\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 return read_wrapper(\n\u001b[1;32m--> 177\u001b[1;33m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                             is_text=False)\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rss_list.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: E722\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                             is_text=False)\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rss_list.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 return read_wrapper(\n\u001b[1;32m--> 173\u001b[1;33m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[0;32m    174\u001b[0m             \u001b[1;31m# compat pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                             is_text=False)\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rss_list.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ed002776c8e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrss_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rss_list.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrss_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(path, compression)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: E722\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: E722\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                 return read_wrapper(\n\u001b[1;32m--> 177\u001b[1;33m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    144\u001b[0m         f, fh = _get_handle(path, 'rb',\n\u001b[0;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                             is_text=False)\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alphaprime\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rss_list.pkl'"
     ]
    }
   ],
   "source": [
    "rss_df = pd.read_pickle('rss_list.pkl')\n",
    "rss_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "188개의 RSS 피드가 존재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 188개의 피드\n",
    "len(rss_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "언론사는 19개 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['조선닷컴', '노컷뉴스', '동아닷컴', '세계일보', '매일경제', '경향닷컴', '한국아이닷컴', '파이낸셜뉴스',\n",
       "       '헤럴드경제', '데이터넷', '탑라이더', '뉴스포스트', '뉴스데일리', '에버뉴스', '주간포커스', '다음뉴스',\n",
       "       '구글뉴스', '중부매일', '르몽드 디플로마티크'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources = rss_df.corp.unique()\n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 19개의 언론사\n",
    "len(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSS 파싱 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_data`라는 이름으로 RSS url을 입력 받으면 내용을 파싱하는 함수를 만들어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    try:\n",
    "        res = requests.get(url)\n",
    "        html = res.text\n",
    "        data = feedparser.parse(html)\n",
    "        print(data.feed.title)\n",
    "        return data\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 작동하는지 실험하기 위해 첫번째 RSS를 골라 테스트 해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corp                                                조선닷컴\n",
       "name                                        [뉴스]오늘의 주요뉴스\n",
       "url     http://myhome.chosun.com/rss/www_section_rss.xml\n",
       "Name: 34, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조선닷컴, [뉴스]오늘의 주요뉴스\n",
    "rss_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = rss_df.iloc[0].url\n",
    "parsed_data = get_data(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`parsed_data`가 잘 출력된것을 확인 할 수 있습니다. 해당 데이터에 들어 있는 기사 갯수는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parsed_data['entries'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기사(article) 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '\\'기생충\\' 흑백판 26일 개봉… \"봉준호 감독이 직접 톤 조절\"',\n",
       " 'title_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': '',\n",
       "  'value': '\\'기생충\\' 흑백판 26일 개봉… \"봉준호 감독이 직접 톤 조절\"'},\n",
       " 'links': [{'rel': 'alternate',\n",
       "   'type': 'text/html',\n",
       "   'href': 'https://news.chosun.com/site/data/html_dir/2020/02/13/2020021301270.html'}],\n",
       " 'link': 'https://news.chosun.com/site/data/html_dir/2020/02/13/2020021301270.html',\n",
       " 'summary': '아카데미 4관왕에 오르며 전 세계에서 흥행하고 있는 봉준호 감독의 영화 \\'기생충\\' 흑백판이 26일 개봉한다.<br><br>13일 CJ엔터테인먼트는 \"봉준호 감독과 홍경표 촬영감독이 한 장면, 한 장면씩 콘트라스트(명암 대비)와 톤 조절 작업을 거친 \\'기생충\\' 흑백판은 컬러와는 또 다른 느낌의 영화를 선보일 것\"이라며 포스터와 예고편을 함께 공개했다.<br>...',\n",
       " 'summary_detail': {'type': 'text/html',\n",
       "  'language': None,\n",
       "  'base': '',\n",
       "  'value': '아카데미 4관왕에 오르며 전 세계에서 흥행하고 있는 봉준호 감독의 영화 \\'기생충\\' 흑백판이 26일 개봉한다.<br><br>13일 CJ엔터테인먼트는 \"봉준호 감독과 홍경표 촬영감독이 한 장면, 한 장면씩 콘트라스트(명암 대비)와 톤 조절 작업을 거친 \\'기생충\\' 흑백판은 컬러와는 또 다른 느낌의 영화를 선보일 것\"이라며 포스터와 예고편을 함께 공개했다.<br>...'},\n",
       " 'updated': '2020-02-13T09:44:30+09:00',\n",
       " 'updated_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=13, tm_hour=0, tm_min=44, tm_sec=30, tm_wday=3, tm_yday=44, tm_isdst=0),\n",
       " 'authors': [{}],\n",
       " 'author': '',\n",
       " 'published': 'Thu, 13 Feb 2020 09:44:30 +0900',\n",
       " 'published_parsed': time.struct_time(tm_year=2020, tm_mon=2, tm_mday=13, tm_hour=0, tm_min=44, tm_sec=30, tm_wday=3, tm_yday=44, tm_isdst=0)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_entries = 1 # article 정보 확인을 위해 임의로 번호를 지정했습니다.\n",
    "article = parsed_data['entries'][num_entries]\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "article은 위와 같이 딕셔너리 형태로 저장돼 있으며 `keys`를 확인하면 아래와 같습니다. 아래와 같이 몇가지 key에 대하여 내용을 확인해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'title_detail', 'links', 'link', 'summary', 'summary_detail', 'updated', 'updated_parsed', 'authors', 'author', 'published', 'published_parsed'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 제목 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'기생충\\' 흑백판 26일 개봉… \"봉준호 감독이 직접 톤 조절\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기사 링크 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://news.chosun.com/site/data/html_dir/2020/02/13/2020021301270.html'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article['link']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기사 요약 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아카데미 4관왕에 오르며 전 세계에서 흥행하고 있는 봉준호 감독의 영화 \\'기생충\\' 흑백판이 26일 개봉한다.<br><br>13일 CJ엔터테인먼트는 \"봉준호 감독과 홍경표 촬영감독이 한 장면, 한 장면씩 콘트라스트(명암 대비)와 톤 조절 작업을 거친 \\'기생충\\' 흑백판은 컬러와는 또 다른 느낌의 영화를 선보일 것\"이라며 포스터와 예고편을 함께 공개했다.<br>...'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article['summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 key에 대한 내용은 직접 확인해 보시면 됩니다. 보통 언론사들은 RSS에서 기사 정보의 일부를 제공하기 때문에 기사 본문 내용을 제공하지 않는 경우가 많습니다. 기사 본문을 파싱은 아래와 같이 `goose3` 모듈을 활용하여 가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### article 본문 파싱하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 손쉽게 기사 본문을 파싱 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Goose({'stopwords_class':StopWordsKorean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<goose3.article.Article at 0x20496bf8088>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = article['link']\n",
    "contents = reader.extract(url=url)\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'기생충' 흑백판 26일 개봉… \"봉준호 감독이 직접 톤 조절\"\n",
      "\n",
      "아카데미 4관왕에 오르며 전 세계에서 흥행하고 있는 봉준호 감독의 영화 '기생충' 흑백판이 26일 개봉한다.\n",
      "\n",
      "\n",
      "\n",
      "13일 CJ엔터테인먼트는 \"봉준호 감독과 홍경표 촬영감독이 한 장면, 한 장면씩 콘트라스트(명암 대비)와 톤 조절 작업을 거친 '기생충' 흑백판은 컬러와는 또 다른 느낌의 영화를 선보일 것\"이라며 포스터와 예고편을 함께 공개했다.\n",
      "\n",
      "\n",
      "\n",
      "그러면서 \"평소 고전 흑백영화에 대한 로망을 가지고 있었던 두 사람은 '마더' 흑백 버전도 작업한 바 있다. 특별 상영, 영화제, 한정판 블루레이로만 공개됐던 '마더' 흑백 버전과 달리 '기생충:흑백판'은 극장 개봉을 통해 보다 많은 관객들에게 흑백만의 미묘한 아름다움과 함께 '기생충'의 강렬함을 새롭게 전할 예정\"이라고 설명했다. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "‘기생충: 흑백판’ 포스터는 배우들의 눈을 가린 파격적인 디자인으로 전 세계적인 패러디 열풍을 일으킨 오리지널 포스터의 흑백 버전이다. 표정도 속내도 읽을 수 없는 극과 극 가족들의 모습과 한구석에 누운 의문의 다리는 두 가족 앞에 펼쳐질 걷잡을 수 없는 사건을 더욱 강렬하게 보여준다. \n",
      "\n",
      "\n",
      "\n",
      "또한 흑백 색채감의 포스터는 봉준호 감독이 선보였던 웃음과 긴장감, 그리고 슬픔까지 담아낸 가족희비극이라는 새로운 장르를 색다르게 즐기게 할 것을 예고한다. '흑과 백, 넘지 못할 선은 없다'라는 카피와 함께 흑과 백의 다른 색으로 눈을 가린 두 가족의 모습은 '기생충'이 가지고 있는 함축적인 메시지를 상징적으로 담아냈다. \n",
      "\n",
      "\n",
      "\n",
      "'기생충'은 지난 9일(현지시각) 미국 캘리포니아주 할리우드 돌비극장에서 열린 제92회 아카데미 시상식에서 작품상을 비롯해 감독상, 각본상, 국제영화상을 수상했다. 특히 영어가 아닌 언어로 만들어진 영화가 작품상을 받은 것은 아카데미 92년 역사상 처음이다.\n"
     ]
    }
   ],
   "source": [
    "print(article.title+'\\n')\n",
    "print(contents.cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 마지막으로 다시한번 Warning - 뉴스도 저작권 보호를 받습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://trello-attachments.s3.amazonaws.com/5b29ec749cfb0d90ada47d03/5e44f83d26cac278468fba3a/7f999b74c43be2474bf541952043b626/image.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "333.913px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
